# PROJECT CONFIGURATION
project_name: "Corporate Text Pipeline - Supply Chain Transparency"
description: "Automated pipeline for downloading and analyzing 10-K filings for supply chain transparency measures"

# =============================================================================
# COLLABORATOR SETTINGS - Each team member sets their name here
# =============================================================================
# This determines your personal folder within the shared Dropbox and your firm list.
# Options: "will", "katelyn", "lachlan"
collaborator: null  # <-- UPDATE THIS to your name (will, katelyn, or lachlan)

# =============================================================================
# DATA ROOT - For collaborative work with shared Dropbox folder
# =============================================================================
# Set this to your shared Dropbox folder path. Leave empty/null to use local data/ directory.
# Examples:
#   Windows: "C:/Users/YourName/Dropbox/corporate-text-pipeline-data"
#   Mac:     "/Users/YourName/Dropbox/corporate-text-pipeline-data"
#   Linux:   "/home/YourName/Dropbox/corporate-text-pipeline-data"
#
# Your data will be stored in: {data_root}/{collaborator}/
# You can also override this via environment variable: DATA_ROOT
data_root: null  # <-- UPDATE THIS to your Dropbox path

# FIRM-YEAR SPECIFICATIONS
# Each collaborator has their own assigned firm-year list
# Update to match your collaborator name: cik_year_will.csv, cik_year_katelyn.csv, cik_year_lachlan.csv
firm_list_file: "data/firm_lists/cik_year_YOUR_NAME.csv"  # <-- UPDATE to your file

# DOWNLOAD SETTINGS
sec_edgar:
  rate_limit: 10  # requests per second (SEC limit)
  user_agent: "your.email@university.edu"  # <-- UPDATE with your actual email (required by SEC)
  filing_types:
    - "10-K"      # Annual report
    # - "10-K/A"  # Amended annual report (uncomment if needed)

# BATCH PROCESSING
batch_size: 100  # firm-years per batch for your RA to process
max_retries: 3   # retry failed downloads

# OUTPUT STRUCTURE
paths:
  raw_10k: "data/raw/10k"
  cleaned_text: "data/processed/cleaned"
  final_scores: "data/processed/scores"
  logs: "logs"
  # Note: CSR paths removed - we'll add later if needed

# TEXT EXTRACTION SETTINGS
text_extraction:
  # Which sections of 10-K to extract (based on Sodhi & Tang 2019)
  sections:
    - "item_1"    # Business description
    - "item_1a"   # Risk factors (KEY for supply chain disclosures)
    - "item_7"    # MD&A (Management Discussion & Analysis)

  # Minimum text length to consider valid (filters out extraction errors)
  min_text_length: 1000  # characters

# LLM API SETTINGS
# Primary: OpenAI GPT 5.2 (approved for use)
# Secondary: Claude API (pending approval, for replication)
llm:
  # Primary provider for scoring
  primary:
    provider: "openai"
    model: "gpt-5.2"
    api_key_env: "OPENAI_API_KEY"
    max_tokens: 4096
    temperature: 0.0  # deterministic for research reproducibility

  # Secondary provider for replication (if approved)
  secondary:
    provider: "claude"
    model: "claude-sonnet-4-20250514"
    api_key_env: "ANTHROPIC_API_KEY"
    max_tokens: 4096
    temperature: 0.0

# SUPPLY CHAIN TRANSPARENCY SCORING DIMENSIONS
# Based on Bateman & Bonanni (2019) and Sodhi & Tang (2019)
scoring:
  dimensions:
    overall: "Overall supply chain transparency score"
    environmental: "Environmental disclosure (carbon, water, waste, etc.)"
    social: "Social/labor disclosure (working conditions, human rights, etc.)"
    depth: "Supply chain depth (Tier-1 only vs multi-tier)"
    verification: "Verification level (self-reported vs third-party audited)"
    quantitative: "Presence of quantitative metrics vs qualitative statements"

  scale_min: 0
  scale_max: 10
